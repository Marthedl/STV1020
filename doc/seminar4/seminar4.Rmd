---
title: "Seminar 4"
author: "Lise Rødland"
date: "March 29, 2021"
output:
  pdf_document: 
    keep_md: yes
  github_document: default
---
I løpet av dette seminaret skal vi: 

1. Repetere litt om innlastning av data. 
2. Missingverdier (NA).
3. Statistiske mål.
4. Univariat analyse.
5. Bivariat analyse.

Først installerer vi nye pakker og laster inn pakkene vi skal bruke i dagens seminar: 

```{r, eval = FALSE}
# Installerer nye pakker
install.packages("stargazer")
```


```{r}
# Laster inn pakker 
library(tidyverse)
library(stargazer)
```

# Laste inn data og ulike typer av data. 
Det neste vi skal gjøre er å laste inn data. Som vi allerede har snakket om så finnes det mange typer data og hver type krever egne koder for innlastning. På Canvas har jeg lastet opp et dokument som oppsummerer litt av dette. I dag skal vi laste inn data i csv.-format ved hjelp av funksjonen `read.csv`:  
```{r}
# For å laste inn .csv-filer
data <- read.csv("../../data/internett.csv")

# For å lagre .csv-filer
write.csv(data, file = "internett_ed.csv")

```

Datasettet heter internettbruk og omhandler internettbruken til italienere. Det betstår av et utvalg variabler hentet fra European Social Survey (ESS) runde 9 (2018). Enhetene er italienske statsborgere og samlet innholder datasettet 2745 observasjoner og 5 variable: 

- Kjonn -- Mann = 1, Kvinne = 2
- Alder -- Alder til respondenten 
- Utdanning -- Antall år med fullført utdanning 
- Tillit -- Tillit til det italienske parlament (0-10), 0 = ingen tillit, 10 = fullstendig tillit 
- Internettbruk -- Hvor ofte bruker respondenten internett? (1-5), 1 = aldri, 5 = hver dag. 

Før vi går videre vil vi se på dataene våre. Disse kodene har vi sett på tidligere, men vi repeterer det igjen. 

Vi kan bruke `View()` til å åpne en egen fane med datasettet vårt
```{r, eval = FALSE}
View(data)
```

Vi kan bruke `head()` til å undersøke de seks første observasjonene og `tail()` til å undersøke de seks siste observasjonene: 

```{r} 
head(data)
tail(data)
```

Vi kan bruker `summary()` på et datasett-objekt for å se målenivå, antall missingverdier og beskrivende statistikk: 

```{r} 
summary(data) 
```


# Missing (NA/Not available)

Det finnes mange grunner til at det er tomme celler/manglende verdier/svar i dataene. I datasett basert på spørreundersøkelser som ESS så kan det hende at noen respondenter ikke har ønsket å svare på alle spørsmål. I andre tilfeller kan det hende vi rett og slett mangler dataen. Vi skal nå se på hvordan vi kan finne missing-verdier og hva vi kan gjøre med dem i R. Men når dere skal gjøre egne analyser så er det er viktig å teoretisk begrunne hvordan man håndterer NA-verdier på bakgrunn av utvalget av populasjonen. Er missing-verdiene systematiske eller er de tilfeldige? 

Når vi skal finne missing er det mest vanlig er å bruke funksjonen `is.na()`. `is.na()` tar utgangspunkt i en logisk test. For hver observasjon i et datasett eller en variabel så sjekker `is.na()` om det finnes missingverdier. Under ser dere et eksempel der jeg spør R om rad 1:6 har missingverdier: 

```{r}
is.na(data %>% 
        slice_head(n = 6))
```
Som dere ser er verdiene i datasettet nå byttet ut med `FALSE` og `TRUE`. `TRUE` indikerer at observasjonen mangler data om denne variabelen. Et eksempel er observasjon/rad nummer 4 som mangler data på tillit-variabelen. `FALSE` indikerer at det finnes data. 

Vi kan kombinere `is.na()` med `sum()` for å finne totalt antall missingverdier. `sum()` kan brukes til å summere, for eksempel:

```{r}
sum(2,2,6)
```
Når `sum()` kombineres med `is.na()` så kan vi tenke oss at `TRUE` gir verdien 1 og `FALSE` gir verdien 0. Det betyr at en observasjon får verdien 1 på en gitt variabel dersom informasjonen mangler og 0 om den ikke mangler. R summerer så opp alle disse verdiene og summen angir antall observasjoner med verdien 1, altså med manglende informasjon.  

```{r}
# Finner ut om de seks første observasjonene har missing på variabelen tilitt
is.na(data %>% 
        slice_head(n = 6) %>%  # Beholder bare de seks første observasjonene
        select(tillit))        # Beholder bare variabelen tillit

# Omdanner TRUE/FALSE til 1/0 ved hjelp av as.numeric
as.numeric(is.na(data %>% 
                   slice_head(n = 6) %>% 
                   select(tillit)))

# Teller antall missing blant de seks første observasjonene
sum(is.na(data %>% 
            slice_head(n = 6) %>% 
            select(tillit)))
```
Vi kan kombinere `sum()` og `is.na()` til å telle totalt antall missingverdier i datasettet vårt. En rad, eller en observasjon, kan ha missing på flere variabler. Denne funksjonen vil telle alle disse. 

```{r}
sum(is.na(data)) 
```

Vi kan kombinere `sum()`, `is.na()` og indeksering ved hjelp av `$` til å hente ut antall missingverdier på en variabel: 

```{r}
sum(is.na(data$internettbruk)) # Viser hvor mange missing det er på en variabel
```

Vi kan kombinere `sum()` med en funksjon som heter `complete.cases()` for å finne ut hvor mange observasjoner vi *ikke* mangler noe informasjon på noen variabler om: 

```{r}
complete.cases(data %>% 
                 slice_head(n = 6))

sum(complete.cases(data)) 
```
Du kan også lese antall missing ut fra `summary`. Legg merke til at NAs (missingverdier) kommer til sist:

```{r}
# For alle variabler i datasettet
summary(data)

# For variabelen internettbrukt
summary(data$internettbruk)

```

I en oppgave så vil en vanligvis kommenterer missingverdier. Vi må også velge hva vi skal gjøre med dem. Det er vanelig å fjerne NA hvis de er 'missing at random' eller 'missing completely at random'. Du kan velge å fjerne alle missing verdier eller bare missing verdier på spesifikke variable. Når vi begynner med analyser så vil R ta høyde for missingverdier og fjerne dem automatisk. Det er som når vi beregner gjennomsnittet - man kan ikke regne gjennomsnittet av missing, derfor må vi si til R hvordan R skal håndtere missing. 

Dersom en ønsker et datasett uten missingverdier så kan man bruke funksjonen `drop_na()`. 
```{r}
# Fjerne alle observajoner med minst en missing  
data1 <- data %>% 
  drop_na() 

# Fjerne alle observasjoner med missing på en variabel (eller fler) 
data2 <- data %>% 
  drop_na(internettbruk) # Du kan legge til flere variable med komma

# Vi skal ikke bruke data1 og data2 mer så jeg fjerner dem fra environment
rm(data1, data2)

```

Når dere skal skrive egne oppgaver så er det viktig å lese kodeboken nøye. Noen ganger kommer manglende data kodet som for eksempel 999 eller 9999. Da kan R tror at dette er en faktisk verdi og ikke en missingverdi. I slike tilfeller må en omkode variabelen før en bruker den i analyser. 


# Statistiske mål
       
Statistiske mål forteller oss noe om fordelingen til ulike variabler, som for eksempel gjennomsnitt, median og standardavvik, men også minimum- og maksimumverdier, typetall og frekvens. Statistiske mål på sentraltendens er gjennomsnitt, median og modus. Som vi har sett tidligere så kan vi få informasjon om dette ved å bruke samlefunksjonen `summary()` eller ved å bruke enkeltfunksjoner som for eksempel `mean()`, `min()` og `max()`. Ved bruk av enkeltfunksjonene så må vi huske å spesifisere `na.rm = TRUE` så R vet hvordan vi ønsker å håndtere missingverdier.  

Statistiske mål på spredning i dataene er standardavviket og varians. Standardavviket viser respondentenes gjennomsnittlige avstand fra gjennomsnittet. Vi kan bruke funksjonen `sd()`. Også her må vi spesifisere `na.rm = TRUE` for at R skal vite hvordan vi ønsker å håndtere missingverdier. Syntaksen for `sd()` er som `mean()`:

```{r, eval = FALSE}
sd(data$variabel, na.rm = TRUE)
```

Om vi ønsker å regne ut standardavviket for internettbruk så skriver vi: 

```{r}
sd(data$internettbruk, na.rm = TRUE)
```

Variansen er standardavviket opphøyd i annen. Dermed er standardavviket kvadratroten av variansen. Det er enklere å tolke standardavvik enn varians. Jeg viser likevel hvordan man finner variansen.

```{r}
# Lagrer variansen i et eget objekt
varians <- var(data$internettbruk, na.rm = TRUE)

# bruker funksjonen sqrt() for å finne kvadratroten
sqrt(varians)
```

Vi kan bruke en logisk test for å sjekke om kvadratroten av variansen gir samme tall som standardavviket:

```{r}
# Lagrer først standardavviket i et objekt: 
stdavvik <- sd(data$internettbruk, na.rm = TRUE)

# Bruker logisk test for å spørre R om standardavviket er det samme som kvadrat-
# roten av variansen
stdavvik == sqrt(varians)

```

Vi skal ikke bruke objektene `stdavvik` og `varians` noe mer så vi fjerner dem fra environment:

```{r}
rm(stdavvik, varians)
```


# Univariat analyse: Deskriptiv statistikk med én variabel.

Når vi kun har én variabel vi vil beskrive, har vi å gjøre med univariate fordelinger. Da blir vi kjent med variablene hver for seg. En univariat fordeling gir oss informasjon om hvordan observasjonene fordeler seg på en variabels ulike verdier. Igjen gir `summary()`-funksjonen en rask oversikt over statistiske mål og deskriptiv statistikk. Det  er her nyttig å gjøre seg godt kjent med de ulike statistiske målene. Men den univariate analysen kan ta ting et skritt videre, med for eksempel tabeller og histogrammer. 

```{r}
summary(data)
```


Det er også lurt å gjøre seg kjent med klassen til variablene. Til det kan vi bruke `tibble()`, `str()` eller `class()`:


```{r}
# tibble og str gir informasjon om hele datasettet
tibble(data)
str(data)

# class gir informasjon om en variabel
class(data$internettbruk)
```

For kategoriske variabler, på nominalnivå eller ordinalnivå, kan vi bruke frekvenstabeller for å beskrive dataene med tall, og kake- og søylediagram for å beskrive dataene grafisk. Kake- og søylediagrammer lager vi ved hjelp av `ggplot()`. Dette så vi nærmere på i seminar tre så se tilbake til notatene derfra for å reptere dette.  
       
Variabelen for kjønn er en kategorisk variabel. En frekvenstabell forteller oss hvor mange respondenter som er menn og hvor mange som er kvinner. Vi kan bruke funksjonen `table()`. `table()` gir kan brukes på en eller to variabler. Her skal vi se på tilfellet med en variabel: 
```{r}
table(data$kjonn)
       
# Lagrer table i et objekt, som vi kan eksportere til Word
tabell <- table(data$kjonn)
tabell1 <- data.frame(tabell)
       
# Bruker stargazer-pakken til å eksportere tabellen
stargazer(tabell1, 
          type = "html",
          out = "../../output/sem4_tabkjonn.htm",
          summary = FALSE)


```

Vi kan gjøre det samme for internettbruk, som er på ordinalnivå. 
       
```{r}

tabell2 <- table(data$internettbruk)
tabell2
      
```

Disse viser den absolutte fordelingen, altså totalt antall observasjoner for hver verdi. Vi kan også få den relative fordelingen mellom kategoriene, som viser prosentvis fordeling. Vi bruker prop.table()-funksjonen
       
       
```{r}
tabell3 <- prop.table(table(data$internettbruk))
tabell3

```
Det er alltid et poeng å lage grafer og figurer for å beskrive dataen. Det gir nemlig et godt visuelt og mer intutitvt inntrykk av dataene. For kategoriske variabler kan vi lage kake- og søylediagram for å beskrive frekvensfordelingene til variablene. 
       
For å få søylediagram bruker vi funksjonen ggplot-funksjonen som er i pakken tidyverse. 
       
```{r}
# Søylediagram for internettbruk
        ggplot(data, aes(internettbruk)) + 
  geom_bar(width = 1)

# Prøv å legg på titler osv... 

 # Her ser vi tydelig at det er flest som oppgir 5 som alternativ 
       

```

         
For kontinuerlige variabler så kan vi også bruke frekvenstabeller, men da må vi først omkode variabelen. Dersom vi lager en frekvenstabell for alder, må vi omkode den til kategorier ved hjelp av `cut()`-funksjonen. I argumentet `breaks =` forteller jeg R hvor mange kategorier det skal være, og hvor skjæringspunktet skal være. Først undersøker jeg variabelen ved hjelp av `summary()`. 
       
```{r}
summary(data$alder) # Min er 16 år, og maks er 90 år. Lager så kategorier

data$alder_kat <- cut(data$alder, 
                            breaks = c(16, 30, 45, 60, 75, 90)) 

table(data$alder_kat)
       
```

Grafiske fremstillinger er også nyttig med kontinuerlige variabler. Da kan vi blant annet bruke histogrammer. Også her må vi dele opp i kategorier. Vi bruker ggplot, men endrer `geom_`. Legg merke til argumentet `bins =` - dette bestemmer hvor mange søyler vi ønsker. Prøv å endre argumentet å se hva som skjer.   

       
```{r}
ggplot(data, aes(alder)) + 
        geom_histogram(bins = 20, 
                       color = "white", 
                       fill = "blue") 

```

         
I en større oppgave ønsker man ofte å presentere alle variablenes deskriptive statistikk i en felles tabell. Funksjonen `stargazer()` er fin til å gjøre dette. 

```{r}
stargazer(data, 
         type = "text")
       
# Vis hvordan du gjøre dette om til html.

```

         
# Bivariat hypotesetesting

Kellstedt og Whitten presenterer tre typer hypotesetester for bivariate sammenhenger som vi skal se på i seminar i dag. Hvilken test som passer avhenger av målenivået på avhengig og uavhengig variabel:

- Kategorisk avhengig og uavhengig variabel: tabellanalyse
- Kontinuelig avhengig og kategorisk uavhengig variabel: sammenligne gjennomsnitt
- Kontinuerlig avhengig og uavhengig variabel: korrelasjonskoeffisient



Bivariat analyse brukes når man analyserer to variabler. Bivariat analyse er nyttig for å få oversikt over sammenhengen mellom to variabler, i tillegg til at det forteller oss noe om hvor mye to variabler korrelerer, altså hvor mye de henger sammen. Bivariat statistikk er også nyttig for å teste korrelasjonens statistiske signifikans. 


## Tabellanalyse
Dersom vi har to kategoriske variabler vi ønsker å sammenlikne så kan vi presentere dem i en krysstabell. Da bruker vi funksjonen `table()`. Vi kan opprette en krysstabell mellom  internettbruk og kjønn i et nytt objekt kalt krysstabell. La oss si at vi har en hypotese om at menn 

Det første vi gjør er å laste inn datasettet `ANES2016small`. Dette er samme datasett som Kellstedt og Whitten bruker. Datasettet er i .Rdata-format så da bruker vi funksjonen `load` til å laste inn data:

```{r}
# Bytt ut det som står i hermetegn med filbanen og filnavnet på din maskin:
load("../../data/ANES2016small.RData")
```

Det første vi skal gjøre er å lage en krysstabell med absolutte antall. Da bruker vi funksjonen `table()`. I dag skal vi lagre krysstabellen i et eget objekt for å kunne bruke den videre. Jeg kaller objektet `krysstabell`:

```{r}
krysstabell <- table(ANES2016small$V2Trump, ANES2016small$female)
```

Denne tabellen oppgir frekvensfordelingen i absolutte tall. Vi kan også finne relative tall, altså andeler ved hjelp av `prop.table`. `prop.table` krever et table-objekt og vi bruker derfor 

       
```{r}
prop.table(krysstabell, margin = 1)
# margin = 1 brukes for å regne ut fordelingen per linje, feks hvor mange 
# menn relativt til kvinner som oppgir 1 på skalaen for internettbruk 
     

```

Kjikvadrattesten tester sammenhengen mellom to kategoriske variabler. Den sammenlikner krysstabellen vi har, men en hypotetisk tabell fra et annet utvalg der det ikke er noen sammeheng mellom variablene. Så tester den sannsynligheten for at tabellen vår er generert ved en tilfeldighet. Vi bruker funksjonen chisq.test()
       
```{r}
chisq.test(krysstabell)
# X-squared, altså kjikvadratet er på 31.18, og 


```

En alternativ måte å gjøre det på er å bruke funksjonen `CrossTable` fra pakken `gmodels`. Da må vi først installere og laste inn pakken: 
```{r, eval = FALSE}
install.packages("gmodels")
```

```{r}
library(gmodels)

CrossTable(ANES2016small$V2Trump, ANES2016small$female)
```


Vi kan lage søylediagrammer for å presentere sammenhengen grafisk. Igjen, det er alltid lurt, også for deg selv. Det er mer intuitivt å tolke, og lettere å se sammenhenger raskt. 
       
```{r}
ggplot(data, aes(x = internettbruk, 
                fill = as.factor(kjonn))) + 
 geom_bar(position = "dodge") + 
labs(fill = "kjonn") 
 
# For relative tall 

ggplot(data, aes(x = internettbruk, 
                fill = as.factor(kjonn))) + 
 geom_bar(position = "fill") + 
labs(fill = "kjonn") 
       
       

```

Vi avslutter med bivariat analyse med to kontinuerlige variabler. Dette er en forsmak på bivariat regresjonsanalyse som vi skal se mer på neste gang. Hensikten med dette  er å beskrive korrelasjonen eller samvariasjonen mellom variablene. Vi kan beskrive denne sammenhengen med Pearsons r eller teste om korrelasjonen er statistisk signifikant.  
       
Pearsons r beskriver styrken og retningen til korrelasjonen mellom to variabler. Den varierer fra -1 (negativ sammenheng) til 1 (positiv sammenheng). 0 indikerer ingen sammenheng. La oss teste med alder og utdanning. Vi bruker funksjonen `cor()`.
       
```{r}
R <- cor(x = data$alder, 
        y = data$utdanning, 
        use = "pairwise.complete.obs")
R
# Hva forteller dette oss?
       

```

Vi kan også sette opp en korrelasjonsmatrise for å utforske alle de bivariate korrelasjonene i datasettet mellom de akutelle variablene. 
       
```{r}
cor(data %>% 
      select_if(is.numeric), use = "pairwise.complete.obs")

```
         
Spredningsdiagrammer egner seg godt for å grafisk fremstille sammenhengen mellom to kontinuerlige variabler. Den viser hvor hver respondent (observasjonsenhet) plasserer seg på x-aksen og y-aksen. Vi bruker ggplot med et annet geom-argument.  
       
```{r}
ggplot(data, aes(alder, utdanning)) + 
geom_point() + 
labs(title = "Sammenhengen mellom utdanning og  internettbruk")

# Hva viser spredningsdiagrammet oss? 

ggplot(data, aes(alder, utdanning, 
color = as.factor(kjonn))) + 
geom_point() + 
labs(title = "Sammenhengen mellom utdanning og internettbruk")

# Plott med linje
ggplot(data, aes(alder, utdanning)) +
geom_smooth(method = "lm")+
labs(title = "Sammenhengen mellom utdanning og internettbruk")

# Plott med linje og punktestimater 

ggplot(data, aes(alder, utdanning)) + 
geom_point() + 
geom_smooth(method = "lm") + 
labs(title = "Sammenhengen mellom utdanning og  internettbruk")

```

Dette er begynnelsen på en regresjonsanalyse, som er tema for neste seminar. 